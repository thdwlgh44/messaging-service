package com.example.messaging_service.messaging.service;

import com.example.messaging_service.messaging.entity.MessageLog;
import com.example.messaging_service.messaging.model.UserEvent;
import com.example.messaging_service.messaging.repository.MessageLogRepository;
import com.fasterxml.jackson.databind.ObjectMapper;
import io.micrometer.core.annotation.Timed;
import io.micrometer.core.instrument.Counter;
import io.micrometer.core.instrument.MeterRegistry;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.stereotype.Service;

import java.util.List;
import java.util.stream.Collectors;

/*
* Kafka ë©”ì‹œì§€ ì†Œë¹„ ë° DB ì €ì¥ (Batch ì²˜ë¦¬ + ë³‘ë ¬ ì²˜ë¦¬ ì ìš©)
* ì‚¬ìš©ì ì´ë²¤íŠ¸ Redis ì €ì¥ ê¸°ëŠ¥ ì¶”ê°€
* */
@Service
public class KafkaConsumerService {

    private final MessageLogRepository messageLogRepository;
    private final Counter messageCounter;
    private final RedisService redisService;
    private final ObjectMapper objectMapper;

    public KafkaConsumerService(MessageLogRepository messageLogRepository, MeterRegistry meterRegistry, RedisService redisService, ObjectMapper objectMapper) {
        this.messageLogRepository = messageLogRepository;
        this.messageCounter = meterRegistry.counter("kafka.consumer.processed.messages"); // Kafka ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰ ì¹´ìš´í„°
        this.redisService = redisService;
        this.objectMapper = objectMapper;
    }

    //ê°œë³„ ë©”ì‹œì§€ë¥¼ ë°›ë„ë¡ ë˜ì–´ìˆìœ¼ë¯€ë¡œ Batch ì²˜ë¦¬ë¥¼ ì§€ì›í•˜ëŠ” ì „ìš© íŒ©í† ë¦¬ í•„ìš” (KafkaConfig.java)
    //ì—¬ëŸ¬ ê°œì˜ ë©”ì‹œì§€ ì˜ˆë¥¼ ë“¤ì–´ 1ì´ˆì— 10,000ê°œì˜ ë©”ì‹œì§€ê°€ ë“¤ì–´ì˜¤ë”ë¼ë„ ì‹±ê¸€ ìŠ¤ë ˆë“œì¸ kafkaì˜ ì²˜ë¦¬ ì§€ì—°ì„ ë§‰ê³  ë³‘ë ¬ ì†Œë¹„ í™œì„±í™”. ì—¬ëŸ¬ ë©”ì‹œì§€ ë™ì‹œ ì²˜ë¦¬ ê°€ëŠ¥.
    @KafkaListener(topics = "message-topic", groupId = "messaging-group", containerFactory = "batchFactory")
    @Timed(value = "kafka.message.process.time", description = "Time taken to process messages")
    public void consumeMessages(List<ConsumerRecord<String, String>> records, Acknowledgment ack) {
        long startTime = System.currentTimeMillis(); // ì²˜ë¦¬ ì‹œê°„ ì¸¡ì • ì‹œì‘

        System.out.println("ğŸ“¥ Batch Received: " + records.size() + " messages");

        List<MessageLog> logs = records.stream().map(record -> {
            String[] parts = record.value().split(":");
            MessageLog log = new MessageLog();
            log.setType(parts[0]);
            log.setRecipient(parts[1]);
            log.setContent(parts[2]);
            return log;
        }).collect(Collectors.toList());

        // í•œ ë²ˆì— ì—¬ëŸ¬ ê°œì˜ ë©”ì‹œì§€ë¥¼ ë°›ì•„ Bulk Insert
        messageLogRepository.saveAll(logs);

        // Kafka ë©”ì‹œì§€ ì²˜ë¦¬ëŸ‰ ì¹´ìš´í„° ì¦ê°€
        messageCounter.increment(records.size());

        long endTime = System.currentTimeMillis(); // ì²˜ë¦¬ ì‹œê°„ ì¸¡ì • ì¢…ë£Œ
        System.out.println("âœ… Batch ì²˜ë¦¬ ì‹œê°„: " + (endTime - startTime) + " ms");

        // ìˆ˜ë™ ì»¤ë°‹ (ì˜¤í”„ì…‹ ê´€ë¦¬) - ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
        ack.acknowledge();
    }

    // âœ… ì‚¬ìš©ì ì´ë²¤íŠ¸ ì²˜ë¦¬ (Redis ì €ì¥)
    @KafkaListener(topics = "user-events", groupId = "messaging-group")
    public void consumeUserEvent(String message) {
        try {
            UserEvent event = objectMapper.readValue(message, UserEvent.class);

            if ("PRODUCT_VIEW".equals(event.getEventType())) {
                redisService.saveUserViewedProduct(event.getUserId(), event.getProductId());
                System.out.println("âœ… Redisì— ì €ì¥ëœ ìµœê·¼ ë³¸ ìƒí’ˆ: " + redisService.getUserViewedProducts(event.getUserId()));
            }
        } catch (Exception e) {
            System.err.println("âŒ JSON ë³€í™˜ ì˜¤ë¥˜: " + e.getMessage());
        }
    }
}
